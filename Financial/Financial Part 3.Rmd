---
title: "Financial Part 3"
---

```{r}
data <- read.csv("finance_data.csv", header=TRUE,sep=";")
data$time=as.Date(data$time)
head(data,6)
```

```{r}
plot(data$time, data$SLV, type="l")
```

## Mixture models
### a) Fit normal mixture models with 2 and 3 components

Kig pÃ¥ Jans kode fra uge 10. Der er det implimenteret for en possion distribution og optimerer derfor over en parameter. Her skal det implementeres for en normal distribution og derfor for to parametre. 

```{r}
## Natural to working parameters
re.norm.mix.pn2pw <- function(m, mu, sigma, delta) {
  if(sum(delta) >= 1) {
    print("sum(delta) should be < 1")
    return()
  }
  t.sigma <- log(c(sigma[1],sigma[-1]-sigma[-m]))
  t.delta <- log(delta/(1 - sum(delta)))
  return(list(mu = mu, t.sigma = t.sigma, t.delta = t.delta))
}

## Working to natural parameters
re.norm.mix.pw2pn <- function(m, mu, t.sigma, t.delta){
  if(m == 1){
    return(exp(t.sigma))
  }
  sigma <- cumsum(exp(t.sigma))
  delta <- exp(t.delta)/(1 + sum(exp(t.delta)))
  delta <- c(1 - sum(delta),delta)
  return(list(mu = mu, sigma = sigma, delta = delta))
}


## Normal mixture: transform
## Natural to working parameters
norm.mix.pn2pw <- function(m, mu, sigma, delta) {
  if(sum(delta) >= 1) {
    print("sum(delta) should be < 1")
    return()
  }
  t.sigma <- log(sigma)
  t.delta <- log(delta/(1 - sum(delta)))
  return(list(mu = mu, t.sigma = t.sigma, t.delta = t.delta))
}

## Working to natural parameters
norm.mix.pw2pn <- function(m, mu, t.sigma, t.delta){
  if(m == 1){
    return(exp(t.sigma))
  }
  sigma <- exp(t.sigma)
  delta <- exp(t.delta)/(1 + sum(exp(t.delta)))
  delta <- c(1 - sum(delta),delta)
  return(list(mu = mu, sigma = sigma, delta = delta))
}

## Negative log likelihood
nll <- function(theta, m=2, x=data$SLV){
  if(m == 1) {
    return(-sum(pnorm(x, theta[1], exp(theta[2]), log=TRUE))) 
  }
  mu <- theta[1:m]
  t.sigma <- theta[(m+1):(2*m)]
  t.delta <- theta[(2*m+1):(3*m-1)]
  n.pars <- norm.mix.pw2pn(m, mu, t.sigma, t.delta)
  n <- length(x)
  nll <- 0
  for(i in 1:n) {
    nll <- nll - log(sum(n.pars$delta * dnorm(x[i], mu, n.pars$sigma)))
  }
  return(nll)
}

```


```{r}
## Estimation with 2 distributions
m <- 2; 

## Initial values
mu <- mean(data$SLV)*c(2,1/2)
sigma <-sd(data$SLV)*c(1,1)
delta <- c(0.01)

## Working parameters
wpars <- norm.mix.pn2pw(m, mu, sigma, delta)
theta <- c(wpars$mu, wpars$t.sigma, wpars$t.delta)

## MLE
opt2 <- nlminb(theta, nll, m = m, x = data$SLV)

## Natural parameters
npars2 <- norm.mix.pw2pn(m, opt2$par[1:m], opt2$par[(m+1):(2*m)], opt2$par[(2*m+1):(3*m-1)])

npars2 
```

```{r}
mix.dist <- function(x ,npars){
  sum(npars$delta * dnorm(x, mean = npars$mu, sd = npars$sigma))
}

## Plot
par(mfrow=c(1,1))
hist(data$SLV, prob=TRUE, nclass=60, main = '2 component model of Weekly Return', xlab = 'Weekly Return')
lines(seq(min(data$SLV), max(data$SLV), 0.001), sapply(seq(min(data$SLV), max(data$SLV), 0.001), mix.dist, npars=npars2), col=2)
lines(seq(min(data$SLV), max(data$SLV), 0.001), npars2$delta[1]*dnorm(seq(min(data$SLV), max(data$SLV), 0.001), npars2$mu[1], npars2$sigma[1]), col=3)
lines(seq(min(data$SLV), max(data$SLV), 0.001), npars2$delta[2]*dnorm(seq(min(data$SLV), max(data$SLV), 0.001), npars2$mu[2], npars2$sigma[2]), col=3)
legend("topleft",  c("2 components",'Components seperately'), col=c("red",'green'), lty=1, cex=0.7)

```


```{r}
## Estimation with 3 distributions
m <- 3;

## Initial values 
mu <- mean(data$SLV)*c(1/2,1,3/2)
sigma <- sd(data$SLV)*c(1/2,1,3/2);
delta <- c(1/3,1/3)

## Working parameters
wpars <- norm.mix.pn2pw(m, mu, sigma, delta)
theta <- c(wpars$mu, wpars$t.sigma, wpars$t.delta)

## MLE
opt3 <-nlminb(theta, nll, m = m, x = data$SLV)

## Natural parameters
npars3 <- norm.mix.pw2pn(m, opt3$par[1:m], opt3$par[(m+1):(2*m)], opt3$par[(2*m+1):(3*m-1)])
npars3
```


```{r}
mix.dist <- function(x ,npars){
  sum(npars$delta * dnorm(x, mean = npars$mu, sd = npars$sigma))
}

## Plot
par(mfrow=c(1,1))
hist(data$SLV, prob=TRUE, nclass=60, main = '3 component model of Weekly Return', xlab = 'Weekly Return')
lines(seq(min(data$SLV), max(data$SLV), 0.001), sapply(seq(min(data$SLV), max(data$SLV), 0.001), mix.dist, npars=npars3), col=2)
lines(seq(min(data$SLV), max(data$SLV), 0.001), npars3$delta[1]*dnorm(seq(min(data$SLV), max(data$SLV), 0.001), npars3$mu[1], npars3$sigma[1]), col=3)
lines(seq(min(data$SLV), max(data$SLV), 0.001), npars3$delta[2]*dnorm(seq(min(data$SLV), max(data$SLV), 0.001), npars3$mu[2], npars3$sigma[2]), col=3)
lines(seq(min(data$SLV), max(data$SLV), 0.001), npars3$delta[3]*dnorm(seq(min(data$SLV), max(data$SLV), 0.001), npars3$mu[3], npars3$sigma[3]), col=3)
legend("topleft",  c("3 components",'Components seperately'), col=c("red",'green'), lty=1, cex=0.7)


```
```{r}
## Model check
AIC <- 2*c(opt2$objective, opt3$objective) + 2*c(length(opt2$par), length(opt3$par))
AIC

## Deviance 
1-pchisq(-2*(opt3$objective-opt2$objective),df=length(opt3$par)-length(opt2$par))

```

Model 2 is slightly better than model 3. The  best model in financial part 1 was the t-distribution with an AIC score of -1492. Therefore this is the overall best model. 


### b) Report confidence interval for the parameters in the best mixture model. 
```{r}
opt2
```

```{r}
npars2$sigma[2]
npars2$delta[1]
```


```{r}
library(numDeriv)
H <- hessian(nll, opt2$par)
se<- sqrt(diag(solve(H)))
(CI1 <- opt2$par[1]+c(-1,1)*se[1]*qnorm(0.975))
(CI2<- opt2$par[2]+c(-1,1)*se[2]*qnorm(0.975))
(CI2<- npars2$sigma[1]+c(-1,1)*se[2]*qnorm(0.975))
(CI2<- npars2$sigma[2]+c(-1,1)*se[2]*qnorm(0.975))
(CI2<- npars2$delta[1]+c(-1,1)*se[2]*qnorm(0.975))
(CI2<- npars2$delta[2]+c(-1,1)*se[2]*qnorm(0.975))


#(CI3 <- opt2$par[3]+c(-1,1)*se[3]*qnorm(0.975))
#(CI4<- opt2$par[4]+c(-1,1)*se[4]*qnorm(0.975))
#(CI5<- opt2$par[5]+c(-1,1)*se[5]*qnorm(0.975))

```
The mean value is centered around zero. Since, sigma is small, little variance in the data is expected. Better interpretation??

## c) Make a profile likelihood plot of one of the variance parameters in the two component model.  

```{r}
source("A1.R")
## Profile likelihood for sigma 1 given working parameters
lp.sigma1 <- function(sigma1, m, x, pars0){
  ## Fun for inner optim
  fun.tmp <- function(theta, sigma1, m, x){
    pars <- c(theta[1:m], log(sigma1), theta[-(1:m)])
    nll(pars, m, x)
  }
  nlminb(pars0, fun.tmp, sigma1 = sigma1, m = m, x = x)$objective    
}

## Estimation with 2 distributions
m <- 2; 

## Initial values
mu <- mean(data$SLV)*c(1/2,3/2)
sigma <-sd(data$SLV)*c(1/2,3/2)
delta <- c(0.1)

## Working parameters
wpars <- norm.mix.pn2pw(m, mu, sigma, delta)
theta0 <- c(wpars$mu, wpars$t.sigma, wpars$t.delta)
theta <- c(theta0[1:m],theta0[(m+2):(3*m-1)])

sigma1 <- seq(0.01, 0.20, length=100)

## profile likeihood
pnll <- sapply(sigma1, lp.sigma1, m = m, x = data$SLV, pars0 = theta)

## Plot the profile likelihood
plot(sigma1,exp(-(pnll-min(pnll))),type="l", ylim=c(0,1), xlab = 'Standard deviation', ylab = 'Profile likelihood')
lines(range(sigma1),
      c(1,1)*exp(-qchisq(0.95,df=1)/2),col=2,lty=2,lwd=2)
rug(npars2$sigma,col=2,lwd=2)
```
We have two maxima in the profile likelihood. Meaning we don't know which one is better.


### d) Int he previous question you shoulds ee multiple maxima,reprametrize the model such that you only see one maximum

Hvordan fungerer denne her reparametrisering

```{r}
## Natural to working parameters
re.norm.mix.pn2pw <- function(m, mu, sigma, delta) {
  if(sum(delta) >= 1) {
    print("sum(delta) should be < 1")
    return()
  }
  t.sigma <- log(c(sigma[1],sigma[-1]-sigma[-m]))
  t.delta <- log(delta/(1 - sum(delta)))
  return(list(mu = mu, t.sigma = t.sigma, t.delta = t.delta))
}

## Working to natural parameters
re.norm.mix.pw2pn <- function(m, mu, t.sigma, t.delta){
  if(m == 1){
    return(exp(t.sigma))
  }
  sigma <- cumsum(exp(t.sigma))
  delta <- exp(t.delta)/(1 + sum(exp(t.delta)))
  delta <- c(1 - sum(delta),delta)
  return(list(mu = mu, sigma = sigma, delta = delta))
}

## Negative log likelihood
re.nll <- function(theta, m, x){
  if(m == 1) {
    return(-sum(pnorm(x, theta[1], exp(theta[2]), log=TRUE))) 
  }
  mu <- theta[1:m]
  t.sigma <- theta[(m+1):(2*m)]
  t.delta <- theta[(2*m+1):(3*m-1)]
  n.pars <- re.norm.mix.pw2pn(m, mu, t.sigma, t.delta)
  n <- length(x)
  nll <- 0
  for(i in 1:n) {
    nll <- nll - log(sum(n.pars$delta * dnorm(x[i], mu, n.pars$sigma)))
  }
  return(nll)
}

```


```{r}

## Profile likelihood for sigma 1 given working parameters
re.lp.sigma1 <- function(sigma1, m, x, pars0){
  ## Fun for inner optim
  fun.tmp <- function(theta, sigma1, m, x){
    pars <- c(theta[1:m], log(sigma1), theta[-(1:m)])
    re.nll(pars, m, x)
  }
  nlminb(pars0, fun.tmp, sigma1 = sigma1, m = m, x = x)$objective    
}

m <- 2; 

## Initial values
mu <- mean(data$SLV)*c(1/2,3/2)
sigma <-sd(data$SLV)*c(1/2,3/2)
delta <- c(0.1)

## Working parameters
wpars <- re.norm.mix.pn2pw(m, mu, sigma, delta)
theta0 <- c(wpars$mu, wpars$t.sigma, wpars$t.delta)
theta <- c(theta0[1:m],theta0[(m+2):(3*m-1)])

sigma1 <- seq(0.01, 0.05, length=100)

## profile likeihood
pnll <- sapply(sigma1, re.lp.sigma1, m = m, x = data$SLV, pars0 = theta)

## Plot the profile likelihood
plot(sigma1,exp(-(pnll-min(pnll))),type="l", ylim=c(0,1), xlab = 'Standard deviation', ylab = 'Profile likelihood')
lines(range(sigma1),
      c(1,1)*exp(-qchisq(0.95,df=1)/2),col=2,lty=2,lwd=2)
rug(npars2$sigma[1],col=2,lwd=2)


```

### D. Discuss Interpretation of the models

We have a model that shows the distribution of the weekly return of the given ETF.
This is a two component mixture model meaning that is must consist of two underlying components. Where one component has significantly more influence than the other.

ANYTHING ELSE???


# Hidden Markov Models

### a) Fit two and three state normal Hidden Markov Models

```{r}
norm.HMM.pn2pw <- function(m, mu, sigma, gamma) {                                              
  t.sigma <- log(sigma)
  t.gamma <- NULL                              
  if (m > 1) {                                            
    foo     <- log(gamma / diag(gamma))           
    t.gamma <- as.vector(foo[!diag(m)])             
  }                                             
  parvect <- c(as.vector(mu), as.vector(t.sigma), 
               as.vector(t.gamma))
  parvect
}  

norm.HMM.pw2pn <- function(m, parvect) {
  mu    <- parvect[1:m]
  epar  <- exp(parvect[-(1:m)]) 
  sigma <- epar[1:m]
  gamma <- diag(m)                                    
  if (m > 1) {                                                  
    gamma[!gamma] <- epar[(m+1):(m*m)]
    gamma         <- gamma / apply(gamma, 1, sum)          
  }                                                   
  delta <- solve(t(diag(m) - gamma + 1), rep(1, m))          
  list(mu = mu, sigma = sigma, gamma = gamma, delta = delta)           
}  

norm.HMM.mllk <- function(parvect, x, m, ...) {
  n        <- length(x)                            
  pn       <- norm.HMM.pw2pn(m, parvect)            
  P        <- rep(NA, m)
  lscale   <- 0                                    
  foo      <- pn$delta  
  for (i in 1:n) {
    for (j in 1:m) {
      P[j] <- dnorm(x[i], mean = pn$mu[j], sd = pn$sigma[j])
    }
    foo    <- foo %*% pn$gamma * P
    sumfoo <- sum(foo)
    lscale <- lscale + log(sumfoo)
    foo    <- foo / sumfoo
  }
  mllk     <- -lscale
  mllk
}

norm.HMM.mle <- function(x, m, mu0, sigma0, gamma0,...) {                                                      
  parvect0 <- norm.HMM.pn2pw(m, mu0, sigma0, gamma0)         
  mod      <- nlm(norm.HMM.mllk, parvect0, x = x, m = m) 
  pn       <- norm.HMM.pw2pn(m, mod$estimate)            
  mllk     <- mod$minimum                              
  np       <- length(parvect0)
  AIC      <- 2 * (mllk + np)                              
  n        <- sum(!is.na(x))                            
  BIC      <- 2 * mllk + np * log(n)                         
  list(mu = pn$mu, sigma = pn$sigma, gamma = pn$gamma, delta = pn$delta, 
       code = mod$code, mllk = mllk, AIC = AIC, BIC = BIC)   
}

########################################################################################################################

## 2 - state 
## Initial values
m <- 2
mu0 <- mean(data$SLV)*c(1/2,3/2)
sigma0 <- sd(data$SLV)*c(1/2,3/2)
gamma0 <- matrix(0.01,ncol = m, nrow = m)
diag(gamma0) <- 1-(m - 1)*gamma0[1,1]

## optimize
fit2 <- norm.HMM.mle(data$SLV, m, mu0, sigma0, gamma0)
fit2


## 3 - state 
## Initial values
m <- 3
mu0 <- mean(data$SLV)*c(1/2,1,3/2)
sigma0 <- sd(data$SLV)*c(1/2,1,3/2)
gamma0 <- matrix(0.01,ncol = m, nrow = m)
diag(gamma0) <- 1-(m - 1)*gamma0[1,1]

## optimize
fit3 <- norm.HMM.mle(data$SLV, m, mu0, sigma0, gamma0)
fit3
```

Vi gÃ¥r videre med model 3, se pÃ¥ AIC. 

### b) For the chosen model report 95% confidence intervals for the working parameters.

```{r}
parvect <- norm.HMM.pn2pw(3,fit3$mu, fit3$sigma, fit3$gamma)
mod <- nlm(norm.HMM.mllk,parvect, x=data$SLV,m=3, hessian=TRUE)

## Organize the result
parvect <- mod$estimate
names(parvect) <- c("mu1","mu2","mu3",
                    "t.sigma1","t.sigma2","t.sigma3",
                    "tau21","tau31","tau12","tau32","tau13","tau23")

se <- sqrt(diag(solve(mod$hessian)))

upper<-parvect+qnorm(0.975)*se
lower<-parvect-qnorm(0.975)*se

cbind(parvect, lower , upper)
```

### c) Report the natural parameters and interpret the result.

```{r}
natural_params<-norm.HMM.pw2pn(3, parvect)
natural_params
```

### d) Compare the following distributions (by plots)

#### The long term distribution of the return.

```{r}
mix.dist <- function(x ,npars){
  sum(npars$delta * dnorm(x, mean = npars$mu, sd = npars$sigma))
}

## Plot
par(mfrow=c(1,1))
hist(data$SLV, prob=TRUE, nclass=60, main="Long Term Distribution", xlab = "Weekly Return")
lines(seq(min(data$SLV), max(data$SLV), 0.001), sapply(seq(min(data$SLV), max(data$SLV), 0.001), mix.dist, npars=natural_params), col=2)
lines(seq(min(data$SLV), max(data$SLV), 0.001), natural_params$delta[1]*dnorm(seq(min(data$SLV), max(data$SLV), 0.001), natural_params$mu[1], natural_params$sigma[1]), col=3)

lines(seq(min(data$SLV), max(data$SLV), 0.001), natural_params$delta[2]*dnorm(seq(min(data$SLV), max(data$SLV), 0.001), natural_params$mu[2], natural_params$sigma[2]), col=3)

lines(seq(min(data$SLV), max(data$SLV), 0.001), natural_params$delta[3]*dnorm(seq(min(data$SLV), max(data$SLV), 0.001), natural_params$mu[3], natural_params$sigma[3]), col=3)

legend("topleft",  c("3 components",'Components seperately'), col=c("red",'green'), lty=1, cex=0.7)

```


#### The 1-step ahead distribution given that you known the current state.

```{r}

mix.dist.new <- function(x ,delta,npars){
  sum(delta * dnorm(x, mean = npars$mu, sd = npars$sigma))
}

#par(mfrow=c(1,3))
op <- par(cex = 1.3)
for (j in 1:3){
  #hist(data$SLV, prob=TRUE, nclass=60, main="Long Term Distribution")
  delta <- natural_params$gamma[j,] # Hver enkelt r?kke er lig delta
plot(seq(min(data$SLV), max(data$SLV), 0.001), sapply(seq(min(data$SLV), max(data$SLV), 0.001), mix.dist.new, delta=delta, npars=natural_params),ylab = "Likelihood",xlab="Weekly return", 
     type="l", main=paste(c("One Step Distribution - State",j), collapse = " "))
   ## Samlede distribution
  
  for (i in 1:3){
   npars <- list("mu"=natural_params$mu[i],"sigma"=natural_params$sigma[i])
    lines(seq(min(data$SLV), max(data$SLV), 0.001), sapply(seq(min(data$SLV), max(data$SLV), 0.001), mix.dist.new, delta=delta[i], npars=npars),col=1+i)}

legend("topright",  c("Total Distribution",'Distribution of State 1','Distribution of State 2','Distribution of State 3'), col=c("black", 2,3,4), lty=1, cex=0.7)
  }
```

### e) Report 95% confidence intervals for some (or all) natural parameters (note that the natural paramters include the stationary distribution).

Confidence interval for $\mu$ and $\sigma$ using walds confidence intervals.
```{r}
## Wald based

# MEAN
mean3 <- natural_params$mu
lowerCI_mean <- mean3+ qnorm(c(0.025))*se[1:3]
upperCI_mean <- mean3+qnorm(c(0.975))*se[1:3]

MEAN <- cbind(lowerCI_mean,mean3,upperCI_mean)
colnames(MEAN) <-c("2.5%","MLE","97.5%")

## SD
# Her indsÃ¦ttes working parameters og tages exp for at gÃ¸re op fra log transformationen
sd3 <- natural_params$sigma 
lowerCI_sd <- exp(parvect[(3+1):(2*3)]+qnorm(c(0.025))*se[(3+1):(2*3)]) 
upperCI_sd <-exp(parvect[(3+1):(2*3)]+qnorm(c(0.975))*se[(3+1):(2*3)])

SD <- cbind(lowerCI_sd,sd3,upperCI_sd)
colnames(SD) <-c("2.5%","MLE","97.5%")
rownames(SD) <-c("SD1","SD2","SD3")

(SD)
(MEAN)
```


Confidence intervals for the natural parameters are found using bootstrap.

```{r}

# Function that generates data from a normal distribution
normal.HMM.generate_sample <- function(n,m,mu,sigma,gamma,delta=NULL) {
  if(is.null(delta)){ delta<-solve(t(diag(m)-gamma+1),rep(1,m))}
  mvect <- 1:m
  state <- numeric(n)
  state[1] <- sample(mvect,1,prob=delta) # start altid ved delta
  for(i in 2:n){
    state[i]<-sample(mvect,1,prob=gamma[state[i-1],])
  }
  x <- rnorm(n,mean=mu[state],sd=sigma[state])
  x
}

## Plot simulated and actual data
par(mfrow=c(1,1))
set.seed(3215)
n <- dim(data)[1]
plot(1:n,data$SLV,type="l",ylab = "Weekly return",xlab = "Time")
for(i in 1:3){
  y <- normal.HMM.generate_sample(n,3,natural_params$mu,natural_params$sigma,natural_params$gamma,
                                  natural_params$delta)
  lines(1:n,y,col=i+1)
}
lines(1:n,data$SLV,lwd=2,ylab = "Weekly return",xlab = "Time")


```


```{r}
# bootstrap
k <- 200
Mu <- matrix(ncol=3,nrow=k)
Sigma <- matrix(ncol=3,nrow=k)
Gamma <- array(dim=c(3,3,k))
Delta <- matrix(ncol=3,nrow=k)
for(i in 1:k){
  y <- normal.HMM.generate_sample(n,3,natural_params$mu,natural_params$sigma,natural_params$gamma,
                                  natural_params$delta)

  opt.hmm3.tmp <- nlminb(parvect,norm.HMM.mllk, x=y, m=3)
  nat.par.tmp <- norm.HMM.pw2pn(m=3,c(opt.hmm3.tmp$par))
  Mu[i, ]<- nat.par.tmp$mu
  Sigma[i, ]<- nat.par.tmp$sigma
  Gamma[ , ,i]<- nat.par.tmp$gamma
  Delta[i, ]<- nat.par.tmp$delta
}
```

```{r}
# take list of values and take CI's from simulation to get uncertainties
tab <- rbind(cbind(natural_params$mu,t(apply(Mu[1:k, ],2,
                                      quantile,probs=c(0.025,0.975)))),
             cbind(natural_params$sigma,t(apply(Sigma[1:k, ],2,
                                         quantile,probs=c(0.025,0.975)))),
             cbind(natural_params$gamma[1, ],
                   t(apply(Gamma[1, ,1:k ],1,quantile,probs=c(0.025,0.975)))),
             cbind(natural_params$gamma[2, ],
                   t(apply(Gamma[2, ,1:k ],1,quantile,probs=c(0.025,0.975)))),
             cbind(natural_params$gamma[3, ],
                   t(apply(Gamma[3, ,1:k ],1,quantile,probs=c(0.025,0.975)))),
             cbind(natural_params$delta,t(apply(Delta[1:k, ],2,
                                         quantile,probs=c(0.025,0.975)))))
rownames(tab) <- c("mean1","mean2","mean3",
                   "sd1","sd2","sd3",
                   "gamma11","gamma12","gamma13",
                   "gamma21","gamma22","gamma33",
                   "gamma31","gamma32","gamma33",
                   "delta1","delta2","delta3")
round(tab,digits=9)

```


### f) Discuss what would be needed in order to make short term (say 1-2 weeks) predictions.
You need to know which state you are currently in. Then you need to know volatility of current state (degree of variance of trading price over time ($\sigma$)). Then you can predict which state you are most likely to be in.
