abline(a=0, b=1, lty=2)
xrange <- range(data.time$time)
t <- seq(xrange[1],xrange[2],length=100)
#LOG LOGISTIC
coef3 <- mod3$coefficients
z31 <- (log(t)-(coef3[1]+coef3[2]+coef3[3]))/mod3$scale
z30 <- (log(t)-(coef3[1]+coef3[2]))/mod3$scale
S31 <- (1+exp(z31))^-1
S30 <- (1+exp(z30))^-1
# get the range for the x and y axis
xrange <- range(data.time$time)
yrange <- range(S30)
# set up the plot
plot(xrange, yrange, type="n", xlab="Hours since test start",
ylab="Probability of survival (cd4=1)",las=1)
#PLOT THE SURVIVAL FUNCTIONS
lines(t, S31, type="l", col=2, lty=1, lwd=2)
lines(t, S30, type="l", col=3, lty=1, lwd=2)
legend('topright',lwd=2,col=c(2,3),legend=c('LL with tx', 'LL without tx'))
mod0=glm(AIDS~1, family = binomial,data = df)
summary(mod0)
mod0=glm(AIDS~1, family = binomial,data = df)
#mod1 = glm(AIDS~AZT, family = binomial,data = df)
#c = loglik()
#c = mod1$null.deviance-mod1$deviance
c = logLik(mod0)-logLik(mod1)
1-pchisq(c, df=1)
#mod1 = glm(AIDS~AZT, family = binomial,data = df)
#c = loglik()
#c = mod1$null.deviance-mod1$deviance
c = logLik(mod0)-logLik(mod1)
1-pchisq(c, df=1)
logLik(mod1)
logLik(mod0)
logLik(mod0)-1
#mod1 = glm(AIDS~AZT, family = binomial,data = df)
#c = loglik()
#c = mod1$null.deviance-mod1$deviance
c = logLik(mod0)-logLik(mod1)
1-pchisq(c, df=1)
1-pchisq(c, df=1)
logLic(mod0)
logLik(mod0)
logLik(mod0)[1]
logLik(mod0)[0]
#mod1 = glm(AIDS~AZT, family = binomial,data = df)
#c = loglik()
#c = mod1$null.deviance-mod1$deviance
c = logLik(mod0)[1]-logLik(mod1)[1]
1-pchisq(c, df=1)
#mod1 = glm(AIDS~AZT, family = binomial,data = df)
#c = loglik()
#c = mod1$null.deviance-mod1$deviance
c = logLik(mod0)[1]-logLik(mod1)[1]
1-pchisq(c, df=1)
logLik(mod1)[1]
logLik(mod0)[1]
#mod1 = glm(AIDS~AZT, family = binomial,data = df)
#c = loglik()
#c = mod1$null.deviance-mod1$deviance
c = logLik(mod0)[1]-logLik(mod1)[1]
1-pchisq(-2*c, df=1)
#mod1 = glm(AIDS~AZT, family = binomial,data = df)
#c = loglik()
#c = mod1$null.deviance-mod1$deviance
c = logLik(mod0)[1]-logLik(mod1)[1]
1-pchisq(-2*c, df=1)
#mod1 = glm(AIDS~AZT, family = binomial,data = df)
#c = loglik()
#c = mod1$null.deviance-mod1$deviance
c = logLik(mod0)[1]-logLik(mod1)[1]
1-pchisq(2*c, df=1)
c
-2*c
mod1$null.deviance-mod1$deviance
#mod1 = glm(AIDS~AZT, family = binomial,data = df)
c = mod1$null.deviance-mod1$deviance
#c = logLik(mod0)[1]-logLik(mod1)[1]
1-pchisq(2*c, df=1)
#mod1 = glm(AIDS~AZT, family = binomial,data = df)
c = mod1$null.deviance-mod1$deviance
#c = logLik(mod0)[1]-logLik(mod1)[1]
1-pchisq(2*c, df=1)
data <- read.delim("Logistic.txt",header = TRUE, sep = "", dec = ".")
data$AIDS_no=data$n-data$AIDS_yes
head(data,2)
n <- sum(data[,3]) #Number of patient #n
k <- sum(data[,2]) #Number of patients with AIDS #Sucesses #k
theta <- k/n #Probability that you have Aids
AZT = c(rep(1,170),rep(0,168))
AIDS = c(rep(1,25),rep(0,145),rep(1,44),rep(0,124))
#Creating a dataframe with data
df = data.frame(AZT,AIDS)
#Creating design matrix
X <- matrix(0, nrow = length(AIDS), ncol = 2)
X[,1] = 1
X[,2] = c(rep(1,data$AIDS_yes[1]), rep(0,data$AIDS_yes[2]), rep(1,data$AIDS_no[1]),rep(1,data$AIDS_no[2]))
#Logistic regression
mod1=glm(AIDS~AZT, family = binomial,data = df)
summary(mod1)
mod0=glm(AIDS~1, family = binomial,data = df)
a = data$AIDS_yes[1]
b = data$AIDS_no[1]
c = data$AIDS_yes[2]
d = data$AIDS_no[2]
(OR=(a*d)/(b*c))
#with confidence interval #95% confidence interval
(lowerOR=exp(log(OR)-qnorm(0.975)*sqrt(1/a+1/b+1/c+1/d)))
(upperOR=exp(log(OR)+qnorm(0.975)*sqrt(1/a+1/b+1/c+1/d)))
#exp(confint(mod1, type='profile'))[2,]
#p.155
#mod1 = glm(AIDS~AZT, family = binomial,data = df)
c = mod1$null.deviance-mod1$deviance
#c = logLik(mod0)[1]-logLik(mod1)[1]
1-pchisq(2*c, df=1)
confint(mod1)
z=coef(mod1)[2]/summary(mod1)$coefficients[2,2]
2*pnorm(z)
1-pchisq(z^2, df=1)
m0 = glm(AIDS ~ 1, family = binomial)
# See def. for pi on p. 259
pi = m0$fit
#Weights for the score and information function
WS <- (AIDS-pi)
WI <- pi*(1-pi)
#t is the transpose
XWS = t(X) %*% WS # Score function
XWI = X * WI #Information matrix (mellemregning)
XWX = t(XWI) %*% X # Information matrix
#The score statistics (HVAD ER DET DER SKER HER?!?)
t(XWS) %*% solve(XWX) %*% XWS
print('p-value:')
1-pchisq(t(XWS) %*% solve(XWX) %*% XWS, df=1)
#Load data
data.time <- read.delim("actg320.txt",header = TRUE, sep = "", dec = ".")
head(data.time,2)
by(data.time$event, data.time$tx, sum)
#From days to years
data.time$YearTime <- data.time$time/365.25
by(data.time$YearTime, data.time$tx, sum)
library(survival)
Surv.Bytx <- survfit(Surv(time, event == 1) ~ tx,
conf.type = "log-log",data = data.time)
(Surv.Bytx)
plot(Surv.Bytx, conf.int = T, las = 1, xlab = "Time",ylab = "Estimated Survival Prob.", col=c(2,3), lwd = 1)
legend("bottomleft", col=2:3, c("Not treated","Treated"), lwd=2)
plot(Surv.Bytx, fun=function(x) { 1- x }, conf.int = T,las = 1, xlab = "Time",
ylab = "Estimated Failure Prob.", col=c(2,3))
legend("topleft", col=c(2,3), c("Male","Female"))
survdiff(Surv(YearTime, event == 1) ~ tx, data = data.time)
mod1 <- survreg(Surv(time, event) ~ tx + cd4,
data = data.time, dist = "weibull")
summary(mod1)
mod3 <- survreg(Surv(time, event) ~ cd4 + tx,
data = data.time, dist = "loglogistic")
summary(mod3)
c(AIC(mod1),AIC(mod3))
confint(mod3)
#Time ratio for bearings
exp(cbind(coef(mod3)[3],confint(mod3)[3, 1], confint(mod3)[3, 2]))
#Time ratio for loads
exp(cbind(coef(mod3)[2],confint(mod3)[2, 1], confint(mod3)[2, 2])*50)
data.time$z <- (log(data.time$time)-mod3$linear.predictors)/mod3$scale
data.time$CS3 <- log(1+exp(data.time$z))
surv3 <- survfit(Surv(CS3, event==1)~1 , data = data.time)
plot(surv3$time, -log(surv3$surv))
abline(a=0, b=1, lty=2)
xrange <- range(data.time$time)
t <- seq(xrange[1],xrange[2],length=100)
#LOG LOGISTIC
coef3 <- mod3$coefficients
z31 <- (log(t)-(coef3[1]+coef3[2]+coef3[3]))/mod3$scale
z30 <- (log(t)-(coef3[1]+coef3[2]))/mod3$scale
S31 <- (1+exp(z31))^-1
S30 <- (1+exp(z30))^-1
# get the range for the x and y axis
xrange <- range(data.time$time)
yrange <- range(S30)
# set up the plot
plot(xrange, yrange, type="n", xlab="Hours since test start",
ylab="Probability of survival (cd4=1)",las=1)
#PLOT THE SURVIVAL FUNCTIONS
lines(t, S31, type="l", col=2, lty=1, lwd=2)
lines(t, S30, type="l", col=3, lty=1, lwd=2)
legend('topright',lwd=2,col=c(2,3),legend=c('LL with tx', 'LL without tx'))
c
logLik(mod0)[1]-logLik(mod1)[1]
#mod1 = glm(AIDS~AZT, family = binomial,data = df)
c = mod1$null.deviance-mod1$deviance
#c = logLik(mod0)[1]-logLik(mod1)[1]
1-pchisq(2*c, df=1)
-2*(logLik(mod0)[1]-logLik(mod1)[1])
mod0=glm(AIDS~1, family = binomial,data = df)
summary(mod0)
#mod1 = glm(AIDS~AZT, family = binomial,data = df)
c = mod1$null.deviance-mod1$deviance
#c = logLik(mod0)[1]-logLik(mod1)[1]
pchisq(c, df=1,lower.tail = F)
mod1 = glm(AIDS~AZT, family = binomial,data = df)
c = mod1$null.deviance-mod1$deviance
#c = logLik(mod0)[1]-logLik(mod1)[1]
pchisq(c, df=1,lower.tail = F)
mod1 = glm(AIDS~AZT, family = binomial,data = df)
#c = mod1$null.deviance-mod1$deviance
c = logLik(mod0)[1]-logLik(mod1)[1]
pchisq(-2*c, df=1,lower.tail = F)
mod1 = glm(AIDS~AZT, family = binomial,data = df)
#c = mod1$null.deviance-mod1$deviance
c = logLik(mod0)[1]-logLik(mod1)[1]
pchisq(-2*c, df=1,lower.tail = F)
mod1 = glm(AIDS~AZT, family = binomial,data = df)
c = mod1$null.deviance-mod1$deviance
#c = logLik(mod0)[1]-logLik(mod1)[1]
pchisq(-2*c, df=1,lower.tail = F)
mod1 = glm(AIDS~AZT, family = binomial,data = df)
c = mod1$null.deviance-mod1$deviance
#c = logLik(mod0)[1]-logLik(mod1)[1]
pchisq(-2*c, df=1,lower.tail = F)
mod1 = glm(AIDS~AZT, family = binomial,data = df)
c = mod1$null.deviance-mod1$deviance
#c = logLik(mod0)[1]-logLik(mod1)[1]
pchisq(-2*c, df=1,lower.tail = F)
mod1$null.deviance-mod1$deviance
-2*(logLik(mod0)[1]-logLik(mod1)[1])
#mod1 = glm(AIDS~AZT, family = binomial,data = df)
mod0=glm(AIDS~1, family = binomial,data = df) #Model kun med intercept
#c = mod1$null.deviance-mod1$deviance
c = logLik(mod0)[1]-logLik(mod1)[1]
pchisq(-2*c, df=1,lower.tail = F)
data <- read.delim("tuno.txt",header = TRUE, sep = " ", dec = ".")
data$pow.obs.norm<-(data$pow.obs)/5000
head(data,6)
data <- read.delim("tuno.txt",header = TRUE, sep = " ", dec = ".")
data$pow.obs.norm<-(data$pow.obs)/5000
head(data,6)
?arma
?arima
plot(data$r.day,data$pow.obs.norm)
plot(data$r.day,data$pow.obs.norm,type='l')
plot(data$r.day,data$pow.obs.norm,type='o')
plot(data$r.day,data$pow.obs.norm,type='l')
plot(data$r.day,data$pow.obs.norm,type='o')
arima(data$pow.obs.norm,order=(1,0,0),include.mean=F)
arima(data$pow.obs.norm,order=c(1,0,0),include.mean=F)
mod1$residuals
mod1 <- arima(data$pow.obs.norm,order=c(1,0,0),include.mean=F)
mod1$residuals
mod1 <- arima(data$pow.obs.norm,order=c(1,0,0),include.mean=F)
acf(mod1$residuals)
acf(mod1$residuals,lag.max = 50)
pacf(mod1$residuals,lag.max=50)
mod1 <- arima(data$pow.obs.norm,order=c(1,0,0),include.mean=F)
par(mfrow(2,1))
mod1 <- arima(data$pow.obs.norm,order=c(1,0,0),include.mean=F)
par(mfrow=c(2,1))
acf(mod1$residuals,lag.max = 50)
pacf(mod1$residuals,lag.max=50)
mod1 <- arima(data$pow.obs.norm,order=c(1,0,0),include.mean=F)
par(mfrow=c(1,2))
acf(mod1$residuals,lag.max = 50)
pacf(mod1$residuals,lag.max=50)
mod1 <- arima(data$pow.obs.norm,order=c(1,0,0),include.mean=F)
par(mfrow=c(2,1))
acf(mod1$residuals,lag.max = 50)
pacf(mod1$residuals,lag.max=50)
e <- cbind(mod1$residuals[1:length(mod1$residuals)-1],diff(mod1$residuals))
e
e <- cbind(mod1$residuals[1:length(mod1$residuals)-1],diff(mod1$residuals))
e
e <- cbind(mod1$residuals[1:length(mod1$residuals)-1],diff(mod1$residuals,1))
e
?diff
e <- cbind(mod1$residuals[1:length(mod1$residuals)-1],mod1$residuals[2:length(mod1$residuals)])
e
e <- cbind(mod1$residuals[1:length(mod1$residuals)-1],mod1$residuals[2:length(mod1$residuals)])
?dnorm
dnorm(x=e,mean=0)
a <- dnorm(x=e,mean=0)
?dnorm
normal.function=function(dat){
# Define likelihood function:
Normal.likelihood=function(params,dat){ -sum(dnorm(x=dat,mean=0, sd=params[1], log=TRUE))}
# Find the optimal parameters using nlimnb:
opt=nlminb(c(0.01),Normal.likelihood, dat=dat)
# Find the Fisher information:
H=hessian(Normal.likelihood,opt$par, dat=dat)
se=sqrt(diag(solve(H)))
CI1=opt$par[1]+c(-1,1)*se[1]*qnorm(0.975)
return(list("opt"=opt,"CI1"=CI1, "se"=se))
}
normal.function(e)
normal.function=function(dat){
# Define likelihood function:
Normal.likelihood=function(params,dat){ -sum(dnorm(x=dat,mean=0, sd=params[1], log=TRUE))}
# Find the optimal parameters using nlimnb:
opt=nlminb(c(0.01),Normal.likelihood, dat=dat)
# Find the Fisher information:
#H=hessian(Normal.likelihood,opt$par, dat=dat)
#se=sqrt(diag(solve(H)))
#CI1=opt$par[1]+c(-1,1)*se[1]*qnorm(0.975)
#return(list("opt"=opt,"CI1"=CI1, "se"=se))
return(list('opt'=opt))
}
normal.function(e)
normal.function=function(dat){
# Define likelihood function:
Normal.likelihood=function(params,dat){ -sum(dnorm(x=dat,mean=0, sd=params[1], log=TRUE))}
# Find the optimal parameters using nlimnb:
opt=nlminb(c(0.01,0.01),Normal.likelihood, dat=dat)
# Find the Fisher information:
#H=hessian(Normal.likelihood,opt$par, dat=dat)
#se=sqrt(diag(solve(H)))
#CI1=opt$par[1]+c(-1,1)*se[1]*qnorm(0.975)
#return(list("opt"=opt,"CI1"=CI1, "se"=se))
return(list('opt'=opt))
}
normal.function(e)
pmvnorm(lower=rep(-Inf, 2), upper=c(Inf, Inf), mean=c(0,0), sigma=cov(e))
library(mvtnorm)
pmvnorm(lower=rep(-Inf, 2), upper=c(Inf, Inf), mean=c(0,0), sigma=cov(e))
library(mvtnorm)
pmvsnorm(lower=rep(-Inf, 2), upper=c(Inf, Inf), mean=c(0,0), sigma=cov(e))
library(mvtnorm)
pmvsnorm(lower=rep(-Inf, 2), upper=c(Inf, Inf), mean=c(0,0), sigma=cov(e))
library(fMultivar)
#library(fMultivar)
pmvsnorm(lower=rep(-Inf, 2), upper=c(Inf, Inf), mean=c(0,0), sigma=cov(e))
#library(fMultivar)
library('MASS')
pmvnorm(lower=rep(-Inf, 2), upper=c(Inf, Inf), mean=c(0,0), sigma=cov(e))
matrix(0,1,0,1,ncol=2)
matrix(c(0,1,0,1,)ncol=2)
matrix(c(0,1,0,1,),ncol=2)
matrix(c(0,1,0,1),ncol=2)
normal.function=function(dat){
# Define likelihood function:
Normal.likelihood=function(params,dat){ -sum(dmvnorm(x=dat, sd=matrix(c(1,params[1],params[1],1),ncol=2), log=TRUE))}
# Find the optimal parameters using nlimnb:
opt=nlminb(c(0.01),Normal.likelihood, dat=dat)
# Find the Fisher information:
#H=hessian(Normal.likelihood,opt$par, dat=dat)
#se=sqrt(diag(solve(H)))
#CI1=opt$par[1]+c(-1,1)*se[1]*qnorm(0.975)
#return(list("opt"=opt,"CI1"=CI1, "se"=se))
return(list('opt'=opt))
}
normal.function(e)
normal.function=function(dat){
# Define likelihood function:
Normal.likelihood=function(params,dat){ -sum(dmvnorm(x=dat, sd=diag(matrix(c(1,params[1],params[1],1)),ncol=2), log=TRUE))}
# Find the optimal parameters using nlimnb:
opt=nlminb(c(0.01),Normal.likelihood, dat=dat)
# Find the Fisher information:
#H=hessian(Normal.likelihood,opt$par, dat=dat)
#se=sqrt(diag(solve(H)))
#CI1=opt$par[1]+c(-1,1)*se[1]*qnorm(0.975)
#return(list("opt"=opt,"CI1"=CI1, "se"=se))
return(list('opt'=opt))
}
normal.function(e)
dmvnorm(x=dat)
dmvnorm(x=e)
#setwd("/Users/akterminsprove/Desktop/DTU/5. Semester/02418 Statistisk Modellering Teori og Anvendelser/Assignments/Financial Data")
data <- read.csv("finance_data.csv", header=TRUE,sep=";")
data$time=as.Date(data$time)
head(data,6)
plot(data$time,data$SLV)
qqnorm(data$SLV, pch = 1, frame = FALSE)
qqline(data$SLV, col = "steelblue", lwd = 2)
normal.function=function(dat){
normal.likelihood=function(params,dat){-sum(dnorm(x=dat,params[1],params[2],log=TRUE))}
#Find the optimal parameters using nlimnb:
opt=nlminb(c(0.001,0.001),normal.likelihood, dat=dat)
# Find the Fisher information:
H=hessian(normal.likelihood,opt$par, dat=dat)
se=sqrt(diag(solve(H)))
CI1=opt$par[1]+c(-1,1)*se[1]*qnorm(0.975)
CI2=opt$par[2]+c(-1,1)*se[2]*qnorm(0.975)
return(list("opt"=opt,"CI1"=CI1, "CI2"=CI2, "se"=se))
}
normal.function(data$SLV)
library(numDeriv)
normal.function=function(dat){
normal.likelihood=function(params,dat){-sum(dnorm(x=dat,params[1],params[2],log=TRUE))}
#Find the optimal parameters using nlimnb:
opt=nlminb(c(0.001,0.001),normal.likelihood, dat=dat)
# Find the Fisher information:
H=hessian(normal.likelihood,opt$par, dat=dat)
se=sqrt(diag(solve(H)))
CI1=opt$par[1]+c(-1,1)*se[1]*qnorm(0.975)
CI2=opt$par[2]+c(-1,1)*se[2]*qnorm(0.975)
return(list("opt"=opt,"CI1"=CI1, "CI2"=CI2, "se"=se))
}
normal.function(data$SLV)
#setwd("/Users/akterminsprove/Desktop/DTU/5. Semester/02418 Statistisk Modellering Teori og Anvendelser/Assignments/Financial Data")
data <- read.csv("finance_data.csv", header=TRUE,sep=";")
data$time=as.Date(data$time)
head(data,6)
plot(data$time,data$SLV)
qqnorm(data$SLV, pch = 1, frame = FALSE)
qqline(data$SLV, col = "steelblue", lwd = 2)
library(numDeriv)
normal.function=function(dat){
normal.likelihood=function(params,dat){-sum(dnorm(x=dat,params[1],params[2],log=TRUE))}
#Find the optimal parameters using nlimnb:
opt=nlminb(c(0.001,0.001),normal.likelihood, dat=dat)
# Find the Fisher information:
H=hessian(normal.likelihood,opt$par, dat=dat)
se=sqrt(diag(solve(H)))
CI1=opt$par[1]+c(-1,1)*se[1]*qnorm(0.975)
CI2=opt$par[2]+c(-1,1)*se[2]*qnorm(0.975)
return(list("opt"=opt,"CI1"=CI1, "CI2"=CI2, "se"=se))
}
normal.function(data$SLV)
x=data$SLV
h<-hist(x, xlab="SLV",
main="Histogram with Normal Curve")
xfit<-seq(min(x),max(x),length=40)
yfit<-dnorm(xfit,normal.function(data$SLV)$opt$par[1],normal.function(data$SLV)$opt$par[2])
yfit <- yfit*diff(h$mids[1:2])*length(x)
lines(xfit, yfit, col="blue", lwd=2)
library(metRology)
t.function=function(dat){
t.likelihood=function(params,dat){
-sum(dt.scaled(x=dat, df=params[1], mean = params[2], sd = params[3], log = TRUE))}
#Find the optimal parameters using nlimnb:
opt=nlminb(c(1,0.001,0.001),t.likelihood, dat=dat)
# Find the Fisher information:
H=hessian(t.likelihood,opt$par, dat=dat)
se=sqrt(diag(solve(H)))
CI1=opt$par[1]+c(-1,1)*se[1]*qnorm(0.975)
CI2=opt$par[2]+c(-1,1)*se[2]*qnorm(0.975)
CI3=opt$par[3]+c(-1,1)*se[3]*qnorm(0.975)
return(list("opt"=opt,"CI1"=CI1, "CI2"=CI2,"CI3"=CI3, "se"=se))
}
t.function(data$SLV)
x=data$SLV
h<-hist(x, xlab="SLV",
main="Histogram with t-curve Curve")
xfit<-seq(min(x),max(x),length=40)
yfit<-dt.scaled(xfit, df=t.function(data$SLV)$opt$par[1],mean = t.function(data$SLV)$opt$par[2],sd =t.function(data$SLV)$opt$par[3])
yfit <- yfit*diff(h$mids[1:2])*length(x)
lines(xfit, yfit, col="blue", lwd=2)
AIC=function(nll,k){
2*k-2*(-nll)}
library(kableExtra)
results =matrix(NA,ncol=11, nrow=2)
colnames(results) = c("","AIC", "DF", "Mean", "Sd", "CI lower DF","CI upper DF","CI lower Mean","CI upper Mean","CI lower Sd","CI upper Sd")
results[1:2,1]=c("Normal Distribution", "t - Distribution")
results[1,2] =round(AIC(normal.function(data$SLV)$opt$objective,2))
results[1,3] =NA
results[1,4] =round(normal.function(data$SLV)$opt$par[1],4)
results[1,5] =round(normal.function(data$SLV)$opt$par[2],4)
results[1,6] = NA
results[1,7] =NA
results[1,8] =round(normal.function(data$SLV)$CI1[1],4)
results[1,9] =round(normal.function(data$SLV)$CI1[2],4)
results[1,10] = round(normal.function(data$SLV)$CI2[1],4)
results[1,11] = round(normal.function(data$SLV)$CI2[2],4)
results[2,2] =round(AIC(t.function(data$SLV)$opt$objective,2))
results[2,3] =round(t.function(data$SLV)$opt$par[1],4)
results[2,4] =round(t.function(data$SLV)$opt$par[2],4)
results[2,5] =round(t.function(data$SLV)$opt$par[3],4)
results[2,6] =round(t.function(data$SLV)$CI1[1],4)
results[2,7] =round(t.function(data$SLV)$CI1[2],4)
results[2,8] =round(t.function(data$SLV)$CI2[1],4)
results[2,9] =round(t.function(data$SLV)$CI2[2],4)
results[2,10] = round(t.function(data$SLV)$CI3[1],4)
results[2,11] = round(t.function(data$SLV)$CI3[2],4)
results %>%kbl() %>%kable_styling(full_width = TRUE)
setwd("C:/Users/perri/OneDrive - Danmarks Tekniske Universitet/Stastistik Modellering/Statistisk-Modellering-/Financial")
data <- read.csv("finance_data.csv", header=TRUE,sep=";")
data$time=as.Date(data$time)
head(data,6)
library(mclust, quietly=TRUE)
library(MASS)
#library(mclust, quietly=TRUE)
fit = Mclust(data$SLV, G=3, model="V")
install.packages("mclust")
library(MASS)
library(mclust, quietly=TRUE)
fit = Mclust(data$SLV, G=3, model="V")
summary(fit)
install.packages("fMultivar")
data <- read.delim("tuno.txt",header = TRUE, sep = " ", dec = ".")
data$pow.obs.norm<-(data$pow.obs)/5000
head(data,6)
plot(data$r.day,data$pow.obs.norm,type='o')
mod1 <- arima(data$pow.obs.norm,order=c(1,0,0),include.mean=F)
par(mfrow=c(2,1))
acf(mod1$residuals,lag.max = 50)
pacf(mod1$residuals,lag.max=50)
e <- cbind(mod1$residuals[1:length(mod1$residuals)-1],mod1$residuals[2:length(mod1$residuals)])
normal.function=function(dat){
# Define likelihood function:
Normal.likelihood=function(params,dat){ -sum(dmvnorm(x=dat, sd=matrix(c(1,params[1],params[1],1),ncol=2), log=TRUE))}
# Find the optimal parameters using nlimnb:
opt=nlminb(c(0.01),Normal.likelihood, dat=dat)
# Find the Fisher information:
#H=hessian(Normal.likelihood,opt$par, dat=dat)
#se=sqrt(diag(solve(H)))
#CI1=opt$par[1]+c(-1,1)*se[1]*qnorm(0.975)
#return(list("opt"=opt,"CI1"=CI1, "se"=se))
return(list('opt'=opt))
}
dmvnorm(x=e)
library('MASS')
library(fMultivar)
library('MASS')
pmvnorm(lower=rep(-Inf, 2), upper=c(Inf, Inf), mean=c(0,0), sigma=cov(e))
library(mvtnorm)
pmvnorm(lower=rep(-Inf, 2), upper=c(Inf, Inf), mean=means, sigma=cov(e))
